# RandomScripts
Collection of arbitrary (perhaps useful) programs and scripts, and occasional one-liners

Most scripts that I've written have a `-h` option, so take a look, and let me know if anything is unclear!

## Categories
1. [De novo assembly-related](README.md#de-novo-assembly-related-scripts)
2. [Annotation-related](README.md#annotation-related-scripts)
3. [Genome-wide statistics](README.md#genome-wide-statistics-programsscripts)
4. [Illumina data parsing](README.md#illumina-data-parsing-scripts)

## Scripts that are not mine:
1. `barcode_splitter.py`

This script is needed by `divideConquerParser.sh`, as it is the main parsing workhorse.  divideConquerParser.sh just preprocesses the files to split into `n` parts, run in parallel on `n` cores, and merge the results back together.

## One-liners:

### Convert FASTQ to unwrapped FASTA (FASTQ can be gzipped, or uncompressed):

`gzip -dcf [FASTQ file] | awk 'NR%4==1||NR%4==2' | sed 's/@/>/' > [FASTA file]`

### Output lengths of longest `N` contigs or scaffolds from an assembly:

`[path to FASTX toolkit]/bin/fasta_formatter -i [assembly FASTA] | awk '/^>/{scafname=$1;}!/^>/{print substr(scafname, 2)"\t"length($0);}' | sort -k2,2nr | head -n[N]`

**Note: FASTX toolkit is available from [Hannon Lab at CSHL](http://hannonlab.cshl.edu/fastx_toolkit/)**

## De novo assembly-related scripts:

### `NX.pl`

Calculates some standard contiguity statistics from an assembly FASTA.  By default, it calculates the N50 and L50 (length-weighted median contig/scaffold size and number, respectively), and all calls to it also indicate the total assembly size, number of contigs/scaffolds in the assembly, length of longest and shortest contig/scaffold, and average contig/scaffold length.  Options include changing the quantile from 50 (e.g. set quantile to 90 to calculate N90 and L90, setting it to 50 is the same as default), and specifying the genome size (e.g. in the default case, to calculate an NG50).

You can pass `-` as the FASTA file path, and the script will read the FASTA from STDIN, so it can easily be incorporated into piped one-liners.

Also, interestingly, with some upstream fiddling to get reads into FASTA format, you can calculate the NRX statistics (like NR25 and NR40) with this script, although it's fairly slow for large numbers of reads.  We're limited by Perl's sort routine's time complexity, unfortunately.

Example usage:
Calculate N50, L50, and other stats for Drosophila melanogaster FlyBase release 6.13 assembly:
`NX.pl dmel-all-chromosome-r6.13.fasta`

Calculate N90, L90, etc. for the same assembly:
`NX.pl dmel-all-chromosome-r6.13.fasta 90`

Calculate the NG50, LG50, etc., assuming G=130,000,000 bp:
`NX.pl dmel-all-chromosome-r6.13.fasta 50 130000000`

Calculate N50 on a gzipped assembly (e.g. from 10x Genomics' Supernova mkoutput):
`gzip -dc MySupernovaAsm.fa.gz | NX.pl -`
or
`NX.pl MySupernovaAsm.fa.gz`
though piping seems to be faster in many cases.

### `manualScaffold.pl`

This was originally developed as a quick way to manually scaffold contigs into chromosome arms.  You must know *a priori* what the order and orientation of contigs needs to be, as you specify a configuration string, or supply an AGP file to dictate how the script sews the contigs together, and how to label the resultant scaffolds.

The configuration string format isn't the most intuitive, but it was easy to come up with.  Defined using the [augmented BNF grammar](https://en.wikipedia.org/wiki/Augmented_Backus%E2%80%93Naur_form):

`config-string = scaffold*(scaffold-delim scaffold)`

`scaffold-delim = "=>"`

`scaffold = scaffold-name record-delim contig*(contig-delim contig)`

`record-delim = ":"`

`contig-delim = "->"`

`contig = contig-name [revcomp]`

`revcomp = "*"`

`contig-name = *(ALPHA / DIGIT / "_" / "|")`

So for example, if I had 3 contigs generated by Quiver polishing of FinisherSC-improved contigs, and I knew that they should be given the scaffold name chr1 and joined as Segkk0|quiver's end with Segkk1|quiver's beginning, and Segkk1|quiver's end with Segkk2|quiver's end, the configuration string would be:

`chr1:Segkk0|quiver->Segkk1|quiver->Segkk2|quiver*`

If there were more scaffolds to make, the configuration string might look like:

`chr1:Segkk0|quiver->Segkk1|quiver->Segkk2|quiver*=>chr2:Segkk3|quiver*->Segkk19|quiver->Segkk8|quiver*`

In fact, the configuration string I used for *D. yakuba* Tai18E2 was:

`X:Segkk0_quiver*->Segkk61_quiver*->Segkk60_quiver->Segkk41_quiver*->Segkk49_quiver=>2L:Segkk46_quiver*->Segkk47_quiver=>2R:Segkk7_quiver*=>3L:Segkk1_quiver*->Segkk54_quiver=>3R:Segkk48_quiver->Segkk55_quiver=>4:Segkk3_quiver*`

### `prepContigsForGenBank.pl`

This script prepares most of the files you'll need for tbl2asn to submit a genome to GenBank.  It takes in a FASTQ (make sure that the contig names comply with GenBank requirements), and outputs an AGP (with filename specified as an argument) and a renamed FASTQ (on STDOUT) in case you need to annotate/relabel any contigs in particular (e.g. mtDNA contig needs a special label to specify a different genetic code).

As seen above with `manualScaffold.pl`, you specify the scaffolding order for the AGP with a configuration string.  Another requirement for submitting to GenBank is that scaffolds cannot have the same name as a contig used to make them.  This is an AGP requirement (though I didn't find it in the format specification...).  Unscaffolded contigs will get placed in the AGP under a scaffold name that is simply the contig name with _scaf appended.

You can specify the gap length and gap type as well, although last I checked NCBI wants them to always be type U and length 100 if you don't actually have an estimate for the gap size.

### `configStringToAGP.pl`

As you can imagine, this script basically does one part of what `prepContigsForGenBank.pl` does.  In fact it was derived from the same code, I just didn't need a FASTQ, just an easy way to get an AGP for quick manual scaffolding.

### `fastqToFastaQual.pl`

Just another script for GenBank submission, where tbl2asn does not accept FASTQs, so you need to generate a .fsa, and optionally a .qual.  This script takes the FASTQ generated by `prepContigsForGenBank.pl` and creates a .fsa and a .qual.  If you don't want to submit with quality scores, make sure to rename the .qual file (or delete it).

## Annotation-related scripts:

### `ScaffoldGFFtoChromosomeGFF.pl`

This was just a quick script I wrote to go from an annotation (GFF) in scaffold coordinate space (in my case, it was the *Heliconius melpomene* v2 assembly) into chromosomal coordinates based on an AGP.  Not sure how many others will need to use this, but it came in handy for Hmel2.

### `extractRegions.pl`

This script extracts specific segments of a FASTA based on the intervals provided by a BED file.  If you extract only exon records from a GFF and convert that to BED, you could then extract all the exons as separate FASTA records.  Same thing with introns, assuming they have records in the GFF.  This is also useful for extracting flanking regions for primer design, etc.

### `extractSites.pl`

The idea here is similar to `extractRegions.pl`, but this script is the predecessor, and was written out of necessity to create a concatenated FASTA record from many identified sites.  I used this script in combination with `identify4foldDegenerateSites.pl`, but that hasn't been uploaded yet.

### `overlappingFeatures.pl`

This script takes in a BED file of intervals you find interesting, and a GFF of features.  It then extracts lines of the GFF that overlap your intervals, and outputs a modified set of GFF lines.  I used this as a preliminary way to screen for genes within tracts of IBD common between multiple white monarchs.

## Genome-wide statistics programs/scripts:

**Note: All C++ programs will safely compile as long as your compiler supports C++11.  I usually compile with `g++ -O3 -g -Wall --std=c++11 -o [program prefix] [program prefix].cpp`.**

### `listPolyDivSites.cpp`

This program expects two FASTAs with identical lengths and identical line-wrap lengths.  It outputs a simple 3 or 4 column TSV, one line per base, with columns as follows:

1. Scaffold ID
2. Position in reference FASTA
3. 1 or 0 indicating whether or not the sample FASTA is polymorphic or divergent relative to the reference FASTA
4. 1 or 0 indicating whether or not either FASTA has an N at this position

A typical call might look like this:

`listPolyDivSites -p -n [reference FASTA] [sample FASTA] | nonOverlappingWindows -n -w [window size in bp] -o [sample prefix]_poly_w[window size in kb]kb.tsv`

### `oneSamplePolyDiv.sh`

This script is a wrapper for finding windowed heterozygosity and rate of fixed differences for one sample against the reference.  It basically just wraps the example line for `listPolyDivSites` in the case of "poly" being specified, and uses the `-d` flag and a different output TSV filename for the "div" case.

### `oneSamplePolyDivPlot.R`

This is a quick R script for making single-sample heterozygosity and rate of fixed difference plots for windows across the genome.  I think I hard-coded the specific set of scaffolds that it subsets out (i.e. the chromosome arms of the *Drosophila melanogaster* subgroup), so you may have to edit that for your own purposes.  And maybe having all scaffolds on the same plot won't suit your purposes.  But it shouldn't be hard to edit the ggplot call to fix that.

### `oneSamplePolyDivPerScaf.sh`

Rather than finding windowed values for heterozygosity and rate of fixed differences, this wrapper averages the statistics across each scaffold.

### `oneSamplePolyDivOverall.sh`

Even broader, this calculates genome-wide heterozygosity and rate of fixed differences for a single sample against the reference.

### `nonOverlappingWindows.cpp`

This program takes a TSV with 3 or 4 columns, and averages the values in the 3rd column over windows of specified length.  Using the `-n` flag leads to omission of positions within the window that have a 1 in the 4th column of the input.  These sites are omitted from both the numerator and denominator of the average, hence we don't bias the estimate by interpreting masked bases as anything other than missing data.

It was originally written to calculate windowed depth using the output of `samtools depth -aa`, but the input format is general enough that most if not all of my stats tools use it.

### `calculateDxy.cpp`

Among the many basic stats we might want to calculate, Dxy and Pi are pretty basic.  This program calculates both, given a TSV that maps FASTA filenames to population numbers, and a list of FASTA filenames as positional arguments. The output has a variable number of columns, dependent on the number of populations specified.  The first four columns will always be:

1. Scaffold ID
2. Position
3. Dxy between populations 1 and 2
4. Whether this site should be omitted

The remaining columns are Dxy and Pi for the various combinations of populations.

Dxy is calculated on a per-site basis, using the generalized equation (pardon the lack of LaTeX interpretation here):

D\_{x, y} = \frac{n}{n-1} \sum\_{i,j \in {A,C,G,T}} 2\*p\_{x,i}\*p\_{y,j}

And Pi is calculated as:

Pi\_{x} = \frac{n}{n-1} \sum\_{i < j} 2\*p\_{x,i}\*p\_{x,j}

These are no longer exclusively for biallelic sites, but do reduce to the biallelic site formulae when i and j are constrained to 1 and 2.  Also, I haven't actually written out the proof yet, but I'm pretty sure that averaging the per-base values across a window is exactly equivalent to the Dxy and Pi you would calculate using Nei's formulae.

Note that you have to omit the first line (a header) in order to pass the output to `nonOverlappingWindows`.  Also, if you want to take the windowed average of something other than D12, you'll need to pipe the output through a quick awk script, e.g. to average windows of the 6th column:

`calculateDxy -p [population map TSV] [FASTA 1] [FASTA 2] [FASTA 3] [...] | awk 'NR>1{print $1"\t"$2"\t"$6"\t"$4;}' | nonOverlappingWindows -n -w [window size in bp] -o [output TSV filename]`

## Illumina data parsing scripts:

### `ReadHistogram.sh`

This quick bash script just simply wraps a one-liner that creates a histogram TSV of the index reads, sorted in descending order by count.  This histogram file is useful as a QC check before parsing, as it usually takes substantially less time to run than parsing.

It's essentially just two columns:

1. Index sequence
2. Count of index reads matching the sequence in column 1

Example usage:
`ReadHistogram.sh MySequencingLane_I1.fastq.gz > MySequencingLane_i7_index_histogram.tsv`

### `labelIndexReadHistogram.pl`

This script is intended to be used in tandem with `ReadHistogram.sh` (and may be piped to), in order to do a quick sanity check on your barcode file.  If the output from this script does not show most or all of your main barcodes with 0 mismatches at the top of the file, you either misspecified your barcodes file (maybe forgot to revcomp the index sequences?) or something went seriously wrong with the sequencing run.  This also gives a first-pass idea of how much error there was in the index read, and how many reads you should expect after parsing.

The output is a modified version of what comes from `ReadHistogram.sh` in that a variable number of columns is added, one per matching barcode from your barcodes file (with up to 2 mismatches).

Example usage:
`ReadHistogram.sh MySequencingLane_I1.fastq.gz | labelIndexReadHistogram.pl -b MySequencingLane_i7_indices.tsv > MySequencingLane_labeled_i7_histogram.tsv`

You may want to save the read histogram to a file, and feed it to `labelIndexReadHistogram.pl` with the `-i` option, in case you need to diagnose barcode file problems without waiting a long time for each run of `ReadHistogram.sh`.

**Note that your barcode file must be a proper TSV (i.e. columns separated by single `\t` characters, NOT spaces.  Many text editors have the annoying behaviour of inputting a certain number of spaces instead of a true tab character.  Using spaces will make the barcode parser output gibberish/fail, and will not produce any labels from this script.**
An easy way to check for tabs in your barcode file is to run `hexdump -C < MySequencingLane_i7_indices.tsv` and examine the output for `09` characters.  The ASCII code for the tab character is 09 in hexadecimal (see [ASCII Table](http://asciitable.com/)

### `divideConquerParser.sh`

This bash script was a simple (read: rushed) attempt to parallelize the slow process of parsing multiple plates out of an Illumina HiSeq 4000 lane.  At one point I was getting parsing jobs timing out after 24 hours, which seemed ridiculous given the embarassingly parallel nature of parsing.

All that happens behind the scenes here is that we split the read files into `n` parts, run `n` parallel instances of the barcode parser `barcode_splitter.py`, and once all are done, we re-merge the split files appropriately, and delete intermediate files.

Example usage:
Use 8 cores for a single-indexed paired-end (so R1, R2, and I1 FASTQ files) dataset:
`divideConquerParser.sh 3 "MyLane_R1.fastq.gz MyLane_R2.fastq.gz MyLane_I1.fastq.gz" 8 MyLane_i7_indices.tsv 3`

Use 8 cores for single-indexed paired-end dataset, but changing the listing order of the files so the index read file is first:
`divideConquerParser.sh 3 "MyLane_I1.fastq.gz MyLane_R1.fastq.gz MyLane_R2.fastq.gz" 8 MyLane_i7_indices.tsv 1`

Use 8 cores for single-indexed single-end dataset, where index read file is last:
`divideConquerParser.sh 2 "MyLane_R1.fastq.gz MyLane_I1.fastq.gz" 8 MyLane_i7_indices.tsv 2`

Use 8 cores to perform the i5 parse of a dual-indexed paired-end dataset (where i5 is the *_I1.fastq.gz file, and i7 is the *_I2.fastq.gz file):
`divideConquerParser.sh 4 "MyLane_R1.fastq.gz MyLane_R2.fastq.gz MyLane_I1.fastq.gz MyLane_I2.fastq.gz" 8 MyLane_i5_indices.tsv 3`

**Note that the 5th (last) argument is the 1-based position of the index read file you want to parse on.  This number must be less than or equal to the total number of read files you would like to parse.
